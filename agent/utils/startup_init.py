"""
åº”ç”¨å¯åŠ¨åˆå§‹åŒ–æ¨¡å—

è´Ÿè´£åœ¨åº”ç”¨å¯åŠ¨æ—¶è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–å·¥ä½œï¼ŒåŒ…æ‹¬ï¼š
- å·¥å…·ç´¢å¼•é¢„çƒ­
- ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
- é…ç½®éªŒè¯

ä½¿ç”¨æ–¹å¼ï¼š
åœ¨åº”ç”¨ä¸»å…¥å£è°ƒç”¨ initialize_application() å‡½æ•°
"""

import asyncio
import os
import logging
from typing import Dict, Any, Optional

from agent.utils.tool_index_manager import tool_index_manager, ensure_tool_index
from utils.config_manager import get_vector_service_config
from agent.streaming import emit_processing_status

logger = logging.getLogger(__name__)


async def initialize_application(
    tools_dir: str = "tools",
    preload_index: bool = True,
    shared: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    åº”ç”¨å¯åŠ¨åˆå§‹åŒ–
    
    Args:
        tools_dir: å·¥å…·ç›®å½•è·¯å¾„
        preload_index: æ˜¯å¦é¢„åŠ è½½å·¥å…·ç´¢å¼•
        shared: å…±äº«çŠ¶æ€ï¼Œç”¨äºäº‹ä»¶å‘é€
        
    Returns:
        åˆå§‹åŒ–ç»“æœå­—å…¸
    """
    init_result = {
        "success": True,
        "components": {},
        "errors": []
    }
    
    logger.info("ğŸš€ å¼€å§‹åº”ç”¨åˆå§‹åŒ–...")
    
    try:
        # 0. æ£€æŸ¥ LLM é…ç½®ï¼ˆä¼˜å…ˆæ£€æŸ¥ï¼‰
        llm_config_result = await _check_llm_config(shared)
        init_result["components"]["llm_config"] = llm_config_result
        
        if not llm_config_result["available"]:
            init_result["errors"].append("LLM API Key æœªé…ç½®")
            logger.warning("âš ï¸ LLM API Key æœªé…ç½®ï¼Œåº”ç”¨å°†æ— æ³•ç”Ÿæˆå†…å®¹")
            logger.warning("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: LLM_API_KEY, LLM_BASE_URL, LLM_MODEL")
            logger.warning("   å‚è€ƒæ–‡æ¡£: é…ç½®LLM_API_KEYæŒ‡å—.md")
        
        # 1. æ£€æŸ¥å‘é‡æœåŠ¡é…ç½®
        vector_config_result = await _check_vector_service_config(shared)
        init_result["components"]["vector_service"] = vector_config_result
        
        if not vector_config_result["available"]:
            init_result["errors"].append("å‘é‡æœåŠ¡ä¸å¯ç”¨")
            logger.warning("âš ï¸ å‘é‡æœåŠ¡ä¸å¯ç”¨ï¼Œå·¥å…·æ¨èåŠŸèƒ½å°†å—é™")
        
        # 2. é¢„åŠ è½½å·¥å…·ç´¢å¼•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if preload_index and vector_config_result["available"]:
            index_result = await _preload_tool_index(tools_dir, shared)
            init_result["components"]["tool_index"] = index_result
            
            if not index_result["success"]:
                init_result["errors"].append(f"å·¥å…·ç´¢å¼•é¢„åŠ è½½å¤±è´¥: {index_result.get('error', 'Unknown error')}")
        
        # 3. å…¶ä»–åˆå§‹åŒ–ä»»åŠ¡å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        
        # åˆ¤æ–­æ•´ä½“åˆå§‹åŒ–æ˜¯å¦æˆåŠŸï¼ˆå…è®¸ LLM é…ç½®ç¼ºå¤±ä½œä¸ºè­¦å‘Šè€Œéé”™è¯¯ï¼‰
        # åªæœ‰é LLM ç›¸å…³çš„é”™è¯¯æ‰æ ‡è®°ä¸ºå¤±è´¥
        critical_errors = [e for e in init_result["errors"] if "LLM" not in e and "å‘é‡æœåŠ¡" not in e]
        init_result["success"] = len(critical_errors) == 0
        
        if init_result["success"]:
            if len(init_result["errors"]) == 0:
                logger.info("âœ… åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
                if shared:
                    await emit_processing_status(shared, "âœ… åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
            else:
                logger.info(f"âœ… åº”ç”¨åˆå§‹åŒ–å®Œæˆï¼ˆæœ‰ {len(init_result['errors'])} ä¸ªè­¦å‘Šï¼‰")
                if shared:
                    await emit_processing_status(shared, f"âœ… åº”ç”¨åˆå§‹åŒ–å®Œæˆï¼ˆæœ‰ {len(init_result['errors'])} ä¸ªè­¦å‘Šï¼‰")
        else:
            logger.warning(f"âš ï¸ åº”ç”¨åˆå§‹åŒ–å®Œæˆï¼Œä½†æœ‰ {len(critical_errors)} ä¸ªé”™è¯¯")
            if shared:
                await emit_processing_status(shared, f"âš ï¸ åº”ç”¨åˆå§‹åŒ–å®Œæˆï¼Œä½†æœ‰ {len(critical_errors)} ä¸ªé”™è¯¯")
        
        return init_result
        
    except Exception as e:
        error_msg = f"åº”ç”¨åˆå§‹åŒ–å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        init_result["success"] = False
        init_result["errors"].append(error_msg)
        return init_result


async def _check_llm_config(shared: Dict[str, Any] = None) -> Dict[str, Any]:
    """æ£€æŸ¥ LLM é…ç½®"""
    try:
        if shared:
            await emit_processing_status(shared, "ğŸ” æ£€æŸ¥ LLM é…ç½®...")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        api_key = os.getenv("LLM_API_KEY")
        base_url = os.getenv("LLM_BASE_URL")
        model = os.getenv("LLM_MODEL")
        
        llm_config = {
            "api_key": api_key,
            "base_url": base_url,
            "model": model
        }
        
        # åˆ¤æ–­é…ç½®æ˜¯å¦å®Œæ•´
        is_available = all([api_key, base_url, model])
        
        result = {
            "available": is_available,
            "config": {
                "api_key_set": bool(api_key),
                "base_url_set": bool(base_url),
                "model_set": bool(model)
            }
        }
        
        if not is_available:
            missing = []
            if not api_key:
                missing.append("LLM_API_KEY")
            if not base_url:
                missing.append("LLM_BASE_URL")
            if not model:
                missing.append("LLM_MODEL")
            result["missing"] = missing
            result["error"] = f"ç¼ºå°‘é…ç½®: {', '.join(missing)}"
        
        if shared:
            status = "âœ… LLM é…ç½®å¯ç”¨" if is_available else "âŒ LLM é…ç½®ä¸å®Œæ•´"
            await emit_processing_status(shared, status)
        
        logger.info(f"{'âœ…' if is_available else 'âŒ'} LLM é…ç½®æ£€æŸ¥: {result}")
        
        return result
        
    except Exception as e:
        return {
            "available": False,
            "error": f"LLM é…ç½®æ£€æŸ¥å¤±è´¥: {str(e)}"
        }


async def _check_vector_service_config(shared: Dict[str, Any] = None) -> Dict[str, Any]:
    """æ£€æŸ¥å‘é‡æœåŠ¡é…ç½®"""
    try:
        if shared:
            await emit_processing_status(shared, "ğŸ” æ£€æŸ¥å‘é‡æœåŠ¡é…ç½®...")
        
        vector_config = get_vector_service_config()
        base_url = vector_config.get("base_url")
        
        if not base_url:
            return {
                "available": False,
                "error": "å‘é‡æœåŠ¡URLæœªé…ç½®",
                "config": vector_config
            }
        
        # æ£€æŸ¥å‘é‡æœåŠ¡å¯ç”¨æ€§
        import requests
        try:
            response = requests.get(f"{base_url}/health", timeout=5)
            available = response.status_code == 200
        except Exception as e:
            available = False
            error = str(e)
        
        result = {
            "available": available,
            "config": vector_config
        }
        
        if not available:
            result["error"] = f"å‘é‡æœåŠ¡ä¸å¯ç”¨: {error if 'error' in locals() else 'Unknown error'}"
        
        if shared:
            status = "âœ… å‘é‡æœåŠ¡å¯ç”¨" if available else f"âŒ å‘é‡æœåŠ¡ä¸å¯ç”¨"
            await emit_processing_status(shared, status)
        
        return result
        
    except Exception as e:
        return {
            "available": False,
            "error": f"å‘é‡æœåŠ¡é…ç½®æ£€æŸ¥å¤±è´¥: {str(e)}"
        }


async def _preload_tool_index(tools_dir: str, shared: Dict[str, Any] = None) -> Dict[str, Any]:
    """é¢„åŠ è½½å·¥å…·ç´¢å¼•"""
    try:
        if shared:
            await emit_processing_status(shared, "ğŸ”¨ é¢„åŠ è½½å·¥å…·ç´¢å¼•...")
        
        # ä½¿ç”¨ç´¢å¼•ç®¡ç†å™¨ç¡®ä¿ç´¢å¼•å­˜åœ¨
        index_name = await ensure_tool_index(
            tools_dir=tools_dir,
            force_reindex=False,  # å¯åŠ¨æ—¶ä¸å¼ºåˆ¶é‡å»ºï¼Œè®©ç®¡ç†å™¨æ™ºèƒ½åˆ¤æ–­
            shared=shared
        )
        
        # è·å–ç´¢å¼•ä¿¡æ¯
        index_info = tool_index_manager.get_index_info()
        
        return {
            "success": True,
            "index_name": index_name,
            "index_info": index_info
        }
        
    except Exception as e:
        error_msg = f"å·¥å…·ç´¢å¼•é¢„åŠ è½½å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return {
            "success": False,
            "error": error_msg
        }


def initialize_application_sync(
    tools_dir: str = "tools",
    preload_index: bool = True
) -> Dict[str, Any]:
    """
    åŒæ­¥ç‰ˆæœ¬çš„åº”ç”¨åˆå§‹åŒ–ï¼ˆç”¨äºéå¼‚æ­¥ç¯å¢ƒï¼‰
    
    Args:
        tools_dir: å·¥å…·ç›®å½•è·¯å¾„
        preload_index: æ˜¯å¦é¢„åŠ è½½å·¥å…·ç´¢å¼•
        
    Returns:
        åˆå§‹åŒ–ç»“æœå­—å…¸
    """
    try:
        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æˆ–ä½¿ç”¨ç°æœ‰çš„
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            initialize_application(tools_dir, preload_index)
        )
        
    except Exception as e:
        return {
            "success": False,
            "components": {},
            "errors": [f"åŒæ­¥åˆå§‹åŒ–å¤±è´¥: {str(e)}"]
        }


async def get_application_status() -> Dict[str, Any]:
    """è·å–åº”ç”¨çŠ¶æ€"""
    return {
        "tool_index": {
            "ready": tool_index_manager.is_index_ready(),
            "info": tool_index_manager.get_index_info()
        },
        "vector_service": await _check_vector_service_config()
    }


# ä¾¿æ·å‡½æ•°
async def ensure_application_ready(shared: Dict[str, Any] = None) -> bool:
    """ç¡®ä¿åº”ç”¨å°±ç»ª"""
    if not tool_index_manager.is_index_ready():
        init_result = await initialize_application(shared=shared)
        return init_result["success"]
    return True


if __name__ == "__main__":
    # æµ‹è¯•åˆå§‹åŒ–
    import asyncio
    
    async def test_init():
        result = await initialize_application()
        print("åˆå§‹åŒ–ç»“æœ:", result)
        
        status = await get_application_status()
        print("åº”ç”¨çŠ¶æ€:", status)
    
    asyncio.run(test_init())
