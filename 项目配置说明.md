# GTPlanner 项目配置说明

## 📋 项目配置状态

### 答案：项目没有默认配置 LLM API Key

**检查结果**:
1. ❌ 项目本身没有配置 API Key
2. ✅ 项目需要调用大模型才能正常工作
3. ⚠️ 当前未配置 LLM API Key，所以无法生成内容

---

## 🔍 详细说明

### 1. 配置来源

#### 从 settings.toml 看：

```toml
[default.llm]
base_url = "@format {env[LLM_BASE_URL]}"  # 从环境变量读取
api_key = "@format {env[LLM_API_KEY]}"    # 从环境变量读取
model = "@format {env[LLM_MODEL]}"        # 从环境变量读取
```

**说明**: 项目完全依赖环境变量，没有预设的默认值

#### 从 openai_client.py 看：

```python
if not self.api_key:
    raise ValueError("OpenAI API key is required...")
```

**说明**: 如果没有 API Key，会抛出错误

---

### 2. 项目是否需要调用大模型？

**答案: 是的，完全依赖大模型**

**证据**:

#### ✅ 必需调用 LLM 的功能

1. **Agent 智能推理** - 需要 LLM 分析需求
2. **Function Calling** - 需要 LLM 决定调用哪个工具
3. **规划生成** - 需要 LLM 生成规划流程
4. **技术调研** - 需要 LLM 分析技术方案
5. **架构设计** - 需要 LLM 生成设计文档
6. **工具推荐** - 需要 LLM 匹配工具

#### ❌ 不需要 LLM 的功能

1. ✅ SSE 连接 - 纯后端功能
2. ✅ 事件流处理 - 数据传输
3. ✅ 会话管理 - 数据库操作
4. ✅ 前端界面 - 纯前端功能

---

### 3. 当前状态

**配置检查**:
```bash
LLM_API_KEY: NOT SET
LLM_BASE_URL: NOT SET
LLM_MODEL: NOT SET
```

**因此**:
- ✅ 服务可以启动
- ✅ API 可以接收请求
- ✅ 事件流程正常
- ❌ **无法调用 LLM 生成实际内容**
- ❌ 返回空结果（new_messages_count: 0）

---

## 💡 为什么服务能启动但没有内容？

### 架构设计

GTPlanner 采用了**优雅降级**设计：

1. **服务启动** - 不检查 LLM 配置
2. **请求接收** - 可以接收请求
3. **LLM 调用时** - 才发现没有 API Key
4. **结果返回** - 返回空结果（不报错）

**好处**:
- 可以快速部署
- 可以先启动再配置
- 便于开发和调试

**问题**:
- 用户体验不友好（没有明显的错误提示）
- 需要手动发现配置缺失

---

## 🎯 配置方式

### 方式 1: 环境变量（推荐）

```powershell
$env:LLM_API_KEY="sk-your-key"
$env:LLM_BASE_URL="https://api.openai.com/v1"
$env:LLM_MODEL="gpt-4"
```

### 方式 2: .env 文件

创建 `.env` 文件：

```env
LLM_API_KEY=sk-your-key
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4
```

### 方式 3: settings.toml（不推荐）

修改 `settings.toml` 直接设置（不推荐，因为会提交敏感信息）：

```toml
[default.llm]
api_key = "sk-your-key"  # ⚠️ 不要这样做
```

---

## 🔧 需要的配置

### 最小配置（运行必需）

**必须有**:
- `LLM_API_KEY` - API 密钥
- `LLM_BASE_URL` - API 基础 URL
- `LLM_MODEL` - 模型名称

**可选**:
- `JINA_API_KEY` - 用于网络搜索功能
- `VECTOR_SERVICE_BASE_URL` - 用于工具推荐
- `LANGFUSE_*` - 用于追踪

---

## 📊 依赖关系

```
用户输入
   ↓
后端接收 ✅ (不需要 LLM)
   ↓
LLM API 调用 ❌ (需要 API Key)
   ↓
LLM 响应 ❌ (需要 API Key)
   ↓
后端处理
   ↓
前端显示 ✅ (不需要 LLM)
```

**当前阻塞点**: LLM API 调用环节

---

## ✅ 总结

### 项目配置状态

1. **没有默认 API Key** ❌
   - 需要用户自己配置
   - 项目不提供测试 API Key

2. **必须配置 LLM** ✅
   - 项目完全依赖大模型
   - 没有离线/模拟模式
   - 没有降级策略

3. **当前状态** ⚠️
   - 服务运行 ✅
   - API 可用 ✅
   - 无法生成内容 ❌
   - **因为缺少 LLM API Key**

### 解决方案

**立即配置 API Key** 才能看到完整的 PRD 生成！

**查看详细配置指南**:
- `配置LLM_API_KEY指南.md`

